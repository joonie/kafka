
## 카프카 컨슈머



  - 주키퍼의 사용 여부에 따라 올드컨슈머와 뉴컨슈머 2가지로 나뉜다.
    - 올드컨슈머
      - 컨슈머의 오프셋을 주키퍼의 지노드에 저장
    - 뉴컨슈머 (사용)
      - 카프카의 토픽에 오프셋을 저장
  
  ​		
  
  - 주요 옵션
  
    - Bootstrap.servers
  
      - 카프카 클러스터는 모든 브로커가 요청을 받을 수 있기 때문에 여러개의 브로커 정보를 기입한다
      - 포맷 : 호스트명1:포트,호스트명2:포트,호스트명3:포트... (ex. Peter-kafka001:9092,Peter-kafka002:9092... )
  
    - fetch.min.bytes
  
      - 한번에 가져올 수 있는 최소 데이터 사이즈
      - 지정한 사이즈보다 작은 경우 요청에 대해 응답하지 않고 데이터가 누적될 때까지 기다린다
  
    - Fetch.max.wait.ms
  
      - Fetch.min.bytes에 의해 설정된 데이터보다 적은 경우 요청에 응답을 기다리는 최대 시간
  
    - Group.id
  
      - 컨슈머가 속한 컨슈머 그룹을 식별하는 식별자
  
    - enable.auto.commit
  
      - 백그라운드로 주기적으로 오프셋을 커밋한다
  
    - Auto.offset.reset (default: latest)
  
      - 카프카에서 초기 오프셋이 없거나 현재 오프셋이 더 이상 존재하지 않는 경우 다음 옵션으로 리셋한다
        - Earliest : 가장 초기의 오프셋값으로 설정
        - latest : 가장 마지막의 오프셋값으로 설정
        - none : 이전 오프셋값을 찾지 못하면 에러
  
    - fetch.max.bytes
  
      - 한번에 가져올 수 있는 최대 데이터 사이즈
  
    - Request.timeout.ms
  
      - 요청에 대해 응답을 기다리는 최대 시간
  
    - session.timeout.ms (default: 10초)
  
      - 컨슈머와 브로커사이의 세션 타임 아웃 시간
        - 브로커가 컨슈머가 살아있는 것으로 판단하는 시간
        - 만약 컨슈머가 코디네이터에게 하트비트를 내보내지 않고 session.timeout.ms이 지나면 해당 컨슈머는 종료되거나 장애가 있는 것으로 판단하고 컨슈머그룹은 리밸런스를 진행한다
        - 값을 낮게 설정하면 실패를 빨리 감지할 수 있지만 가비지컬렉션이나 poll 루프를 완료하는 시간이 길어지게 되면 원치않은 리밸런스가 일어나기도 한다.
  
    - Heartbeat.interval.ms
  
      - 그룹 코디네이터에게 얼마나 자주 poll() 메소드로 하트비트를 보낼 것인지 조정한다.
      - session.timeout.ms와 밀접한 관련이 있으며 session.timeout.ms의 1/3정도의 크기로 세팅해야한다.
  
    - Max.poll.interval.ms
  
      - 컨슈머가 하트비트는 계속 보내는데 실제 데이터를 가져가지 않는 경우가 있을 수 있다
      - 이런 경우 컨슈머가 무한정 파티션을 점유하지 않도록 주기적으로 poll을 하지 않으면 장애로 판단할 수 있게 해준다
  
    - Auto.commit.interval.ms
  
      - 주기적으로 오프셋을 커밋하는 시간
  
      
  
  - 컨슈머 그룹
  
    - 컨슈머를 생성하려면 반드시 컨슈머 그룹이 있어야한다 (없다면 컨슈머 추가시 자동으로 그룹이 생성됨)
    - 컨슈머 그룹 보기
  
    ```sh
    Kafka-consumer-groups.sh
    ```
  
    - 컨슈머 예시
  
    ```JAVA
    Properties props = new Properties();
    props.put("bootstap.servers", "peter-kafka001:9092,peter-kafka002:9092,peter-kafka003:9092"); //브로커 리스트
    props.put("group.id", "peter-consumer"); //컨슈머 그룹ID
    props.put("enable.auto.commit", "true"); //주기적으로 커밋
    props.put("auto.offset.reset", "latest"); //earliest는 토픽의 처음부터 메세지를 가져오고 latest는 토픽의 가장 마지막부터 메세지를 가져온다. default로 latest
    props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer"); //key가 String
    props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer"); //value가 String
    
    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
    consumer.subscribe(Arrays.asList("peter-topic"));
    
    while(true) {
      ConsumerRecords<String, String> records = consumer.poll(100); //데이터가 컨슈머 버퍼에 없다면 poll을 얼마나 유지할지 조정, 0으로 조정하면 poll은 즉시 리턴(=종료)되고 값을 넣으면 그 시간동안 메세지를 대기한다.
      for(COnsumerRecord<String, String> record : records) {
        //record는 토픽, 파티션, 파티션의 오프셋, key, value를 포함한다.
      	record.topic, record.partition(), record.offset(), record.key(), record.value()
      }
    }
    ```



- 컨슈머 그룹

  - ![consumer group](/img/consumer_group.png)

  

  

  - 카프카 큐에 쌓인 메세지를 컨슘하는 속도가 느리다면 컨슈머그룹에 속한 컨슈머를 늘려서 대응해야한다.

    - 컨슈머를 늘린다(3->4)하더라도 파티션의 개수(3)가 적다면 컨슈머 1개는 놀게 된다 (max 컨슈머개수 = 파티션개수)

    - 위와 반대로 파티션이 컨슈머보다 많다면 하나의 컨슈머는 복수의 파티션으로 부터 메세지를 받게 된다
    - 컨슈머그룹안에서 컨슈머를 추가(리벨런스)하면 일시적으로 컨슈머는 메세지를 가져올 수 없는 단점이 있다



- 커밋과 오프셋

  - 컨슈머가 poll()을 할 때마다 컨슈머그룹은 카프카에 저장되어 있는 아직 읽지 않은 메세지를 가져온다

  - 오프셋의 현재위치를 기록(in 토픽)하는 동작을 커밋이라고 한다

  - 카프카는 커밋과 오프셋 정책으로 인하여 언제든 중복 데이터가 들어올 수 있다는 것을 가정해야한다. (손실은 없다고봐도 무방)

  - 자동커밋

    - enable.auto.commit=true로 설정하며 auto.commit.interval.ms(default:5초)로 커밋주기를 조정한다
    - poll()로 데이터를 가져올때마다 5초 경과 여부를 체크하고 5초가 됐다면 가장 마지막에 한 poll() 요청으로 가져온  오프셋을 커밋한다, 다시말해 poll()을 계속 하다가 5초가 되면 그 직전 poll()의 오프셋을 커밋함.
    - 단점
      - 컨슈머가 그룹내 추가되는 경우 데이터 중복이 발생한다. 커밋 인터벌을 줄이더라도 중복 발생은 불가피하다
      - 컨슈머 1번이 commit을 하고 poll()을 하고 있는 중(AAA받음)에 컨슈머 2가 추가되는 경우 이것도 commit이 아직 안되었기 때문에 컨슈머 1번과 동일한 메세지(AAA)를 받게된다.
      - 또한 커밋이 되었다하더라도 가져온 메세지가 DB에 저장하기 전에 장애가 났다면 메세지 손실이 될수도 있다

  - 수동커밋

    - poll() 이후 커밋하기 이전에 DB에 저장하는 등 자유롭게 로직을 구성할 수 있다. (=커밋 시점을 조절할 수 있음)

    - ```JAVA
      try {
        while(true) {
          ConsumerRecords<String, String> records = consumer.poll(100); //데이터가 컨슈머 버퍼에 없다면 poll을 얼마나 유지할지 조정, 0으로 조정하면 poll은 즉시 리턴(=종료)되고 값을 넣으면 그 시간동안 메세지를 대기한다.
          for(ConsumerRecord<String, String> record : records) {
            //record는 토픽, 파티션, 파티션의 오프셋, key, value를 포함한다.
            record.topic, record.partition(), record.offset(), record.key(), record.value();
            try {
              insertIntoBD(); //커밋이전에 DB에 저정하는 코드를 넣으면 메세지 손실을 막을 수 있다.
              consumer.commitSync(); //오토 커밋이 아니기 때문에 수동으로 커밋을 해줘야 한다.
            } catch(CommitFailedException e) {
              System.out.println("Error", e);
            } 
          }
        }
      } finally { 
        consumer.close();
      }
      ```

      

    - 단점
      - DB에 저장하다가 문제가 생기면 Auto.offset.reset이  기본값인 latest라는 전제하에 마지막에 커밋된 오프셋부터 메세지를 다시 가져오기 때문에 데이터의 중복이 발생할 수 있다.

  - 특정 파티션에 할당

    - 보통은 공평하게 파티션들이 나눠서 처리하길 바라지만 간혹 특정 파티션에서 제어하고자하는 니즈가 생긴다

      - Key-value 형태로 파티션에 저장되어 있고 특정 파티션에 대한 메세지들만 가져와야 하는 경우

    - 예시

    - ```java
      TopicPartition partition0 = new TopicPartition(topic, 0);
      TopicPartition partition1 = new Topicpartition(topic, 1);
      consumer.assign(Arrays.asList(partition0, partition1));
      //consumer.subscribe(Arrays.asList("peter-topic")); 와 같이 subscribe하지 않고 assign을 함
      //중요한건 컨슈머인스턴스마다 컨슈머그룹아이디를 서로 다르게 설정해야한다.
      //동일 컨슈머그룹아이디 내에서는 오프셋을 공유하기 때문에 동작이 이상하게 되기 때문이다.
      
      //seek()을 통해 컨슈머가 다음 poll()하는 위치를 지정할 수 있다
      consumer.seek(partition0, 2); //0,1번 오프셋은 건너뛰고 2번 오프셋부터 메세지를 가져온다.
      consumer.seek(partition1, 2); //0,1번 오프셋은 건너뛰고 2번 오프셋부터 메세지를 가져온다.
      
      try { 
        while(true) {
          ConsumerRecords<String, String> records = consumer.poll(100);
          for(ConsumerRecord<String, String> record : records) {
            try {
              consumer.commitSync();
            } catch(CommitFailedException e) {
              sout(e);
            }
          }
        }
      } finally {
        consumer.close()
      }
      ```

    

    